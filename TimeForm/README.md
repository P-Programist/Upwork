# Timeform



Author: Konstantin(DaemonsFighter) Slivnoi
Packages: (
                Python, 
                SQLite3, 
                openpyxl, 
                requests, 
                cloudscraper, 
                BeautifulSoup4
            )



Architecture:
    1. Run file - run.py
    2. File with software configurations - settings.py
    3. File with Database control and transactions logic - db.py
    4. Database with scraped since 2021-01-01 - results.db
    5. Logs made by script during its work - events.log
    6. Folder with XLSX files that were generated by the program - XLSX/
    7. Dependencies for the smooth work of the program ->  requirements.txt



How to install dependencies:
    pip install -r requirements.txt
                or
    pip3 install -r requirements.txt



How to run the program:
    python3 run.py



Steps of execution:
    Step 1: Run the program

    Step 2: The program asks for OPTIONAL filters that you may set up from the beginning.
            IMPORTANT: If you set up a filter, You will get data related to this filter ONLY.
                       It means that if you set up a Race Type filter - there will be data only about that specific Race Type.
            There are two filters:
                1. Race Type filter
                2. Distance filter
            There is an opportunity to set up either one or both filters.

    Step 3: The program starts to scrape information about today's available races.
            There is Anti-Bot protection on the timeform.com website, so the delay between each request to the site in 5 seconds.
            Because of the 5 seconds delay, it may take from 20 to 30 minutes to scrape data about upcoming races.

    Step 4: The program tries to check whether You have already scraped data for today.
            Since every time you run the program it tries to save the data into the database, there is protection from duplicates

    Step 5: In case there is new data on the site, the program starts to scrape it.
            There is Anti-Bot protection on the timeform.com website, so the delay between each request to the site in 5 seconds.
            Due to the 5 seconds delay, it may take from 10 to 20 minutes to scrape data about past races.

    Step 6: When all the scrapping is done the data is saved into the results.db database.

    Step 7: It is reasonable to scrape only those races that are not started yet, 
                so if a race is either already finished or just started it will not be an accountant.
            The most profitable time to run the program before any race has started.

    Step 8: When there is a request to generate data for:
                Last Month, 
                Last Three Month
                Last Year 
            the program makes Query requests to the database.
            Based on set up filters and all configurations there will be generated specific SQL requests to fetch specific rows.
            If there is any data based on set up filters it goes through formulas that were predefined in advance.

    Step 9: When the race's data was fetched from the database and modified by formulas it was supposed to be saved in XLSX files according to a timeline.

    Step 10: The program creates an XLSX folder next to the run.py file 
            and generates 3 files with data for different periods and dumps the data into that.